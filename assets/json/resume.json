{"basics":{"name":"Yun Zhang","label":"First year PhD student at UCLA's Mobility Lab","image":"prof_pic.jpg","email":"yun666@g.ucla.edu","phone":"(310) 694-6791","url":"https://HandsomeYun.github.io/","summary":"Researcher specializing in autonomous driving, computer vision, and physical intelligence.","location":{"address":"","postalCode":"CA 90024","city":"Los Angeles","countryCode":"US","region":"California"}},"education":[{"institution":"University of California, Los Angeles (UCLA)","location":"United States","url":"https://www.ucla.edu/","studyType":"PhD","area":"Mobility Lab","startDate":"2025-09-01","score":"11"},{"institution":"University of California, Los Angeles (UCLA)","location":"United States","url":"https://www.ucla.edu/","studyType":"Undergraduate","area":"B.S. in Mathematics in Computer Science, B.S. in Statistics and Data Science","startDate":"2021-09-01","endDate":"2025-06-15","score":"10","courses":["Cumulative GPA: 3.823/4.0","Dean's Honors List (Fall 2021, Winter/Spring/Fall 2022, Winter/Spring 2023)"]},{"institution":"American Community School of Athens (ACS Athens)","location":"Athens, Greece","url":"https://www.acs.gr/","studyType":"High School","startDate":"2015-09-01","endDate":"2021-06-15","score":"9","courses":["Weighted Cumulative GPA: 4.886/4.0","Final IB Score: 44/45"]}],"publications":[{"name":"MIC-BEV: Multi-Infrastructure Camera Bird's-Eye-View Transformer with Relation-Aware Fusion for 3D Object Detection","publisher":"Submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), Best Paper Award for DriveX Workshop","releaseDate":"2025-09-01","url":"http://arxiv.org/abs/2510.24688","author":"<u>Yun Zhang</u>, Zhaoliang Zheng, Johnson Liu, Zhiyu Huang, Zewei Zhou, Zonglin Meng, Tianhui Cai, and Jiaqi Ma","summary":"First Author. MIC-BEV is a Transformer-based framework for multi-camera infrastructure perception. It performs 3D object detection and BEV segmentation by fusing features from multiple cameras through a geometry-aware graph module. Designed for diverse camera setups and harsh conditions, MIC-BEV maintains strong robustness under sensor degradation. To support this, we introduce M2I, a synthetic dataset covering varied layouts, weather, and viewpoints. Experiments on both M2I and the real-world RoScenes dataset show that MIC-BEV achieves state-of-the-art performance and reliability for real-world deployment. (Currently releasing the Workshop version)"},{"name":"V2XPnP: Vehicle-to-Everything Spatio-Temporal Fusion for Multi-Agent Perception and Prediction","publisher":"Accepted by International Conference on Computer Vision (ICCV)","releaseDate":"2025-03-09","url":"https://arxiv.org/abs/2412.01812","summary":"Sixth Author. V2XPnP proposes a spatio-temporal fusion framework for multi-agent perception and prediction, leveraging a Transformer-based architecture and a novel sequential dataset to benchmark when, what, and how to fuse information in V2X scenarios."},{"name":"RelMap: Enhancing Online Map Construction with Class-Aware Spatial Relation and Semantic Priors","publisher":"Submitted to The 40th Annual AAAI Conference on Artificial Intelligence (AAAI)","releaseDate":"2025-03-09","summary":"Second Author. RelMap is an online HD map construction framework that enhances vectorized map generation using class-aware spatial relations and semantic priors, significantly improving accuracy and data efficiency on nuScenes and Argoverse 2 datasets."},{"name":"AgentAlign: Misalignment-Adapted Multi-Agent Perception for Resilient Inter-Agent Sensor Correlations","publisher":"Submitted to The IEEE/CVF Winter Conference on Applications of Computer Vision 2026 (WACV)","releaseDate":"2025-03-09","url":"https://arxiv.org/abs/2412.06142","summary":"Second Author. This work presents AgentAlign, a real-world multi-agent perception framework that mitigates multi-modality misalignment in cooperative autonomous systems using cross-modality feature alignment and introduces the V2XSet-Noise dataset for robust evaluation."},{"name":"InSPE: Rapid Evaluation of Heterogeneous Multi-Modal Infrastructure Sensor Placement","publisher":"Submitted to The IEEE/CVF Winter Conference on Applications of Computer Vision 2026 (WACV)","releaseDate":"2025-03-09","url":"https://arxiv.org/abs/2504.08240","summary":"Co-firsr Author. This paper introduces InSPE, a framework for evaluating heterogeneous multi-modal infrastructure sensor placement by integrating metrics like sensor coverage, occlusion, and information gain, supported by a new dataset and benchmarking experiments to optimize perception in intelligent intersections."},{"name":"AutoVLA: Vision-Language-Action Model for End-to-End Autonomous Driving with Adaptive Reasoning and Reinforcement Fine-Tuning","publisher":"Accepted by Neural Information Processing Systems (NeurIPS)","releaseDate":"2025-03-09","url":"https://autovla.github.io/","summary":"Fourth Author. AutoVLA is a vision-language-action model for end-to-end autonomous driving with adaptive reasoning and reinforcement fine-tuning capabilities."}],"research":[{"name":"Mobility Lab, UCLA","position":"Research Assistant","url":"https://mobility-lab.seas.ucla.edu/","startDate":"2023-02-01","endDate":"2025-09-01","summary":"Contributed to multi-agent perception, sensor fusion, and infrastructure-aware autonomous driving, co-authoring five papers on multi-modal sensor placement (InSPE), misalignment adaptation in cooperative perception (AgentAlign), class-aware map construction (RelMap), spatio-temporal fusion for V2X perception (V2XPnP), and real-world cooperative perception datasets (V2X-ReaLO).","highlights":["Participating in the U.S. DOT Intersection Safety Challenge and won $750,000"]},{"name":"Vwani Roychowdhury's Lab, UCLA","position":"Research Assistant","url":"https://www.vwaniroychowdhury.com/","startDate":"2023-01-01","endDate":"2024-12-01","summary":"Contributed to the implementation and deep learning models of Hilbert (HIL) detector of PyHFO, a multi-window desktop application providing time-efficient HFO detection algorithms for artifact and HFO with spike classification","highlights":["Reduced the detection run-time by 50 times compared to state-of-the-art with comparative study to ensure correctness."]},{"name":"HKU Summer Research Program","position":"Researcher","url":"https://gradsch.hku.hk/news_and_events/news_and_future_events/summer-research-programme-2024","startDate":"2024-05-01","endDate":"2024-08-20","summary":"Leveraged Large Language Models (MiniGPT-4) for multi-modality brain tumor segmentation, integrating four distinct MRI modalities (T1c, T1w, T2c, and FLAIR) onto a common space to enhance segmentation accuracy.","highlights":["Awarded Best Presenter and received a PhD offer with a Presidential Scholarship."]}],"work":[{"name":"Office of Palo Alto Councilmember Greg Tanaka","position":"AI/Data Analyst Intern","url":"https://example.com","startDate":"2023-06-01","endDate":"2023-12-01","summary":"Analyzed voter data from public social media, HubSpot, and voter profiles within a California congressional district, identifying trends and developing predictive models to anticipate voting behavior","highlights":["Utilized LLMs to generate personalized campaign emails and campaign services, increasing efficiency."]},{"name":"Uber, Hong Kong","position":"Data Analysis Intern","url":"https://www.uber.com/global/en/r/cities/hong-kong-hong-kong-hk/","startDate":"2022-12-01","endDate":"2023-03-01","summary":"Participated in the facial mask recognition project during the COVID-19 pandemic for backend utilities","highlights":["Performed in-depth analysis and demand forecasting for Uber's regional operations, evaluating the influence of factors such as humidity, wind, time of day, as well as origin and destination"]}],"skills":[{"name":"Autonomous Systems & Simulation","level":"Advanced","icon":"fa-solid fa-car","keywords":["CARLA","OpenCDA","OpenSCENARIO Documentation","Scenario Runner"]},{"name":"Multi-Agent & Cooperative Perception","level":"Advanced","icon":"fa-solid fa-network-wired","keywords":["V2X","Cooperative Perception","Sensor Fusion","Multi-Agent Perception","Intermediate Fusion","Multi-Sensor Misalignment"]},{"name":"Programming Languages","level":"Advanced","icon":"fa-solid fa-hashtag","keywords":["Python","C++","JavaScript","C#","R","LaTeX","Bash/Shell Scripting"]},{"name":"Machine Learning & Data Science","level":"Advanced","icon":"fa-solid fa-brain","keywords":["Pytorch","TensorFlow","Scikit-learn","Pandas","NumPy","MATLAB","Jupyter Notebooks"]},{"name":"Medical Imaging & Biomedical Analysis","level":"Advanced","icon":"fa-solid fa-x-ray","keywords":["Segment Anything Model (SAM)","nnUNet","BraTS","Image Segmentation"]},{"name":"DevOps & Cloud Computing","level":"Intermediate","icon":"fa-solid fa-cloud","keywords":["Docker","AWS","Git","GitKraken"]},{"name":"Web Development & Frontend Technologies","level":"Intermediate","icon":"fa-solid fa-code","keywords":["React","Node.js","HTML","CSS","JavaScript","Tableau"]}],"languages":[{"language":"Chinese","fluency":"Native speaker","icon":""},{"language":"English","fluency":"Fluent","icon":""}],"interests":[{"name":"Cooking","icon":"fa-solid fa-utensils","keywords":["Chinese Cuisine","Japanese Cuisine","Western Cuisine","Desserts","Fusion Cooking"]}]}